{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'tree kangaroos', 'narwhals']\n",
      "[('like', 'VERB')]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"I like tree kangaroos and narwhals.\")\n",
    "\n",
    "print([chunk.text for chunk in doc.noun_chunks])\n",
    "#verbs\n",
    "print([(w.text, w.pos_) for w in doc if w.pos_ == \"VERB\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['medspacy_pyrush', 'medspacy_target_matcher', 'medspacy_context']\n",
      "[(stroke, False, False, True), (diabetes, False, True, False), (pna, True, False, False)]\n"
     ]
    }
   ],
   "source": [
    "import medspacy\n",
    "from medspacy.ner import TargetRule\n",
    "\n",
    "nlp = medspacy.load()\n",
    "print(nlp.pipe_names)\n",
    "\n",
    "nlp.get_pipe('medspacy_target_matcher').add([TargetRule('stroke', 'CONDITION'), TargetRule('diabetes', 'CONDITION'), TargetRule('pna', 'CONDITION')])\n",
    "doc = nlp('Patient has hx of stroke. Mother diagnosed with diabetes. No evidence of pna.')\n",
    "print([(ent, ent._.is_negated, ent._.is_family, ent._.is_historical) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Apple', 'ORG'), ('San Francisco', 'GPE')]\n"
     ]
    }
   ],
   "source": [
    "from spacy.lang.en import English\n",
    "\n",
    "nlp = English()\n",
    "ruler = nlp.add_pipe(\"entity_ruler\")\n",
    "patterns = [{\"label\": \"ORG\", \"pattern\": \"Apple\"},\n",
    "            {\"label\": \"GPE\", \"pattern\": [{\"LOWER\": \"san\"}, {\"LOWER\": \"francisco\"}]}]\n",
    "ruler.add_patterns(patterns)\n",
    "\n",
    "doc = nlp(\"Apple is opening its first big office in San Francisco.\")\n",
    "print([(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Apple', 'ORG', 'apple'), ('San Francisco', 'GPE', 'san-francisco')]\n",
      "[('Apple', 'ORG', 'apple'), ('San Fran', 'GPE', 'san-francisco')]\n"
     ]
    }
   ],
   "source": [
    "from spacy.lang.en import English\n",
    "\n",
    "nlp = English()\n",
    "ruler = nlp.add_pipe(\"entity_ruler\")\n",
    "patterns = [{\"label\": \"ORG\", \"pattern\": \"Apple\", \"id\": \"apple\"},\n",
    "            {\"label\": \"GPE\", \"pattern\": [{\"LOWER\": \"san\"}, {\"LOWER\": \"francisco\"}], \"id\": \"san-francisco\"},\n",
    "            {\"label\": \"GPE\", \"pattern\": [{\"LOWER\": \"san\"}, {\"LOWER\": \"fran\"}], \"id\": \"san-francisco\"}]\n",
    "ruler.add_patterns(patterns)\n",
    "\n",
    "doc1 = nlp(\"Apple is opening its first big office in San Francisco.\")\n",
    "print([(ent.text, ent.label_, ent.ent_id_) for ent in doc1.ents])\n",
    "\n",
    "doc2 = nlp(\"Apple is opening its first big office in San Fran.\")\n",
    "print([(ent.text, ent.label_, ent.ent_id_) for ent in doc2.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Apple', 'ORG'), ('San Francisco', 'GPE')]\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "ruler = nlp.add_pipe(\"span_ruler\")\n",
    "patterns = [{\"label\": \"ORG\", \"pattern\": \"Apple\"},\n",
    "            {\"label\": \"GPE\", \"pattern\": [{\"LOWER\": \"san\"}, {\"LOWER\": \"francisco\"}]}]\n",
    "ruler.add_patterns(patterns)\n",
    "\n",
    "doc = nlp(\"Apple is opening its first big office in San Francisco.\")\n",
    "print([(span.text, span.label_) for span in doc.spans[\"ruler\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('MyCorp Inc.', 'ORG'), ('U.S.', 'GPE')]\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "# only annotate doc.ents, not doc.spans\n",
    "config = {\"spans_key\": None, \"annotate_ents\": True, \"overwrite\": False}\n",
    "ruler = nlp.add_pipe(\"span_ruler\", config=config)\n",
    "patterns = [{\"label\": \"ORG\", \"pattern\": \"MyCorp Inc.\"}]\n",
    "ruler.add_patterns(patterns)\n",
    "\n",
    "doc = nlp(\"MyCorp Inc. is a company in the U.S.\")\n",
    "print([(ent.text, ent.label_) for ent in doc.ents])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Dr. Alex Smith', 'PERSON'), ('first', 'ORDINAL'), ('Acme Corp Inc.', 'ORG')]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.language import Language\n",
    "from spacy.tokens import Span\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "@Language.component(\"expand_person_entities\")\n",
    "def expand_person_entities(doc):\n",
    "    new_ents = []\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"PERSON\" and ent.start != 0:\n",
    "            prev_token = doc[ent.start - 1]\n",
    "            if prev_token.text in (\"Dr\", \"Dr.\", \"Mr\", \"Mr.\", \"Ms\", \"Ms.\"):\n",
    "                new_ent = Span(doc, ent.start - 1, ent.end, label=ent.label)\n",
    "                new_ents.append(new_ent)\n",
    "        else:\n",
    "            new_ents.append(ent)\n",
    "    doc.ents = new_ents\n",
    "    return doc\n",
    "\n",
    "# Add the component after the named entity recognizer\n",
    "nlp.add_pipe(\"expand_person_entities\", after=\"ner\")\n",
    "\n",
    "doc = nlp(\"Dr. Alex Smith chaired first board meeting of Acme Corp Inc.\")\n",
    "print([(ent.text, ent.label_) for ent in doc.ents])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "acbe944587e9153b3760fe6bdea35fbf77e65f6dcc869406197e5f964786d5ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
